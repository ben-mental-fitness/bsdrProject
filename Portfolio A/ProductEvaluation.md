Product Evaluation
===
### summary 
- approach used ( questionnaire)
- gave them access via link, small company, small user group
- how documented insights and feedback from evaluation
- how we used finding to refine final iterations of system

---

### Why Evaluate
We evaluate so we can judge how good each release is and to systematically evaluate the product to make the necessary improvements

---

### Evaluation Approach 
Our evaluation approach consisted of; questionnaire, observation
<!--giving the client access to regularly deployed updates, meetings, asking questions, questions-->
we wanted to find out... 
-	What do we want to know we have to improve about UI
-	How usable is product
        -	Should meet client’s requirements
        -	Try it out, couple clicks
-	Efficient, reliable, satisfying, learnable, maintainable, safe, secure, accessible, memorable, configurable, available


####Questionnaire
1.	On a scale of 1-10 how technically minded would you say you are? About how long did it take you to get to grips with MicroStrategy?
1.	Observe how well they get on with figuring out how the system works?
        1.	How many button clicks on average
        1.	How many trace backs
        1.	How many times asking for help/clarification
1.	Where would you have assumed the buttons to export the visualisation would have been?
1.	How well do you think the other BSDR employees (coders) will manage with getting use to this new visualisation software?
1.	On a scale of 1-10 how well does our product translate the features you needed from MicroStrategy?
1.	What features from MicroStrategy may be missing from our product?
1.	Do you have a need to be able to change the text on nodes or edges?


---

### Acting on Feedback
#### 1st
<!--first, filtering based on node weight-->

#### 2nd
<!--final one, weigh on nodes-->



---

### 